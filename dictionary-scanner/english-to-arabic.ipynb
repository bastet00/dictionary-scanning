{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('transilieration-to-arabic.json') as json_file:\n",
    "    computerLatinToArabicText = json.load(json_file)\n",
    "\n",
    "with open('signs_mapper.json') as json_file:\n",
    "    signs_mapper = json.load(json_file)\n",
    "\n",
    "with open('dictionary.json') as json_file:\n",
    "    dictionary = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromTransliterationToArabicAlphabet(word):\n",
    "  arabic_word = \"\"\n",
    "  if( not word):\n",
    "     return \"\"\n",
    "  if(word[0] == 'i'):\n",
    "      arabic_word += \"إ\"\n",
    "  else:\n",
    "        try:\n",
    "            arabic_word += computerLatinToArabicText[word[0]]\n",
    "        except:\n",
    "            print(word)\n",
    "            \n",
    "  for letter_index in range(1, len(word)):\n",
    "        if(word[letter_index] == '.'):\n",
    "            continue\n",
    "        arabic_word += computerLatinToArabicText[word[letter_index]]\n",
    "  return arabic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words= []\n",
    "missing = []\n",
    "for word in dictionary:\n",
    "    arabic_word = fromTransliterationToArabicAlphabet(word['Egyptian'])\n",
    "    try:\n",
    "        sign = signs_mapper[word['Symbol'][-1]]\n",
    "    except:\n",
    "        missing.append(word['Symbol'][-1])\n",
    "    word['ArabicAlphabet'] = arabic_word    \n",
    "    word['Sign'] = sign\n",
    "    words.append(word)\n",
    "    # print(word['Translation'], sign, arabic_word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11770"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Iterate over words in batches\n",
    "for word_index in range(0, len(words)):\n",
    "  # Translate batch\n",
    "  translated_batch = GoogleTranslator(\n",
    "    source='en', target='ar'\n",
    "    ).translate_batch(words[word_index]['Translation'])\n",
    "  words[word_index]['Arabic'] = translated_batch\n",
    "  print(word_index)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Egyptian': 'mr',\n",
       " 'Symbol': ['N36', 'N21', 'Z1'],\n",
       " 'Translation': ['canal', 'artificial lake'],\n",
       " 'ArabicAlphabet': 'مر',\n",
       " 'Sign': '𓏤',\n",
       " 'Arabic': ['قناة', 'بحيرة اصطناعية']}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[5813]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"words.json\", \"w\") as outfile: \n",
    "    json.dump(words, outfile, indent = 4, ensure_ascii=False, sort_keys=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     \"Arabic\": [{\"Word\": \"هرم\"}],\n",
    "#     \"Egyptian\": [{\n",
    "#         \"Word\": \"مر\",\n",
    "#         \"Symbol\": \"𓉴\",\n",
    "#         \"Transliteration\": \"mr\",\n",
    "#         \"Hieroglyphics\": [\"O24\"]\n",
    "#         }\n",
    "#     ]\n",
    "# }\n",
    "def wordToRavenDBInput(word):\n",
    "    return {\n",
    "    \"Arabic\": [{\"Word\": arabic_word} for arabic_word in word['Arabic']],\n",
    "    \"Egyptian\": [{\n",
    "        \"Word\": word['ArabicAlphabet'],\n",
    "        \"Symbol\": word['Sign'],\n",
    "        \"Transliteration\":  word['Egyptian'],\n",
    "        \"Hieroglyphics\": word['Symbol']\n",
    "        }\n",
    "    ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arabic': [{'Word': '(فعل) يحمل'}, {'Word': 'يدعم'}],\n",
       " 'Egyptian': [{'Word': 'فاإ',\n",
       "   'Symbol': '𓀜',\n",
       "   'Transliteration': 'fAi',\n",
       "   'Hieroglyphics': ['A9', 'A24']}]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordToRavenDBInput(words[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 posted successfully\n",
      "Batch 2 posted successfully\n",
      "Batch 3 posted successfully\n",
      "Batch 4 posted successfully\n",
      "Batch 5 posted successfully\n",
      "Batch 6 posted successfully\n",
      "Batch 7 posted successfully\n",
      "Batch 8 posted successfully\n",
      "Batch 9 posted successfully\n",
      "Batch 10 posted successfully\n",
      "Batch 11 posted successfully\n",
      "Batch 12 posted successfully\n",
      "Batch 13 posted successfully\n",
      "Batch 14 posted successfully\n",
      "Batch 15 posted successfully\n",
      "Batch 16 posted successfully\n",
      "Batch 17 posted successfully\n",
      "Batch 18 posted successfully\n",
      "Batch 19 posted successfully\n",
      "Batch 20 posted successfully\n",
      "Batch 21 posted successfully\n",
      "Batch 22 posted successfully\n",
      "Batch 23 posted successfully\n",
      "Batch 24 posted successfully\n",
      "Batch 25 posted successfully\n",
      "Batch 26 posted successfully\n",
      "Batch 27 posted successfully\n",
      "Batch 28 posted successfully\n",
      "Batch 29 posted successfully\n",
      "Batch 30 posted successfully\n",
      "Batch 31 posted successfully\n",
      "Batch 32 posted successfully\n",
      "Batch 33 posted successfully\n",
      "Batch 34 posted successfully\n",
      "Batch 35 posted successfully\n",
      "Batch 36 posted successfully\n",
      "Batch 37 posted successfully\n",
      "Batch 38 posted successfully\n",
      "Batch 39 posted successfully\n",
      "Batch 40 posted successfully\n",
      "Batch 41 posted successfully\n",
      "Batch 42 posted successfully\n",
      "Batch 43 posted successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "# Define the batch size\n",
    "batch_size = 200\n",
    "\n",
    "# Iterate over words in batches\n",
    "for i in range(0, len(words), batch_size):\n",
    "  # Get the current batch\n",
    "  batch = words[i:i+batch_size]\n",
    "  batch_input = []\n",
    "  for word in batch:\n",
    "    batch_input.append(wordToRavenDBInput(word))\n",
    "  # Post the batch to the website\n",
    "  response = requests.post('https://bastet-server-ef94bb4e91eb.herokuapp.com/bulk', json={\"words\": batch_input})\n",
    "  time.sleep(5)\n",
    "  # Check the response status code\n",
    "  if response.status_code == 201:\n",
    "    print(f\"Batch {i//batch_size+1} posted successfully\")\n",
    "  else:\n",
    "    print(f\"Failed to post batch {i//batch_size+1}\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words.json') as json_file:\n",
    "    words = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for word in words: \n",
    "  word['ArabicAlphabet'] = fromTransliterationToArabicAlphabet(word['Egyptian'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arabic': ['بدوي'], 'ArabicAlphabet': 'منثو', 'Egyptian': 'mnTw', 'Sign': '𓏪', 'Symbol': ['Y5', 'X1', 'G43', 'C248', 'Z3'], 'Translation': ['Bedouin']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for word in words: \n",
    "  symbols = [ symbol for symbol in word['Symbol'] if symbol]\n",
    "  if(symbols[-1] in ['Z1', 'Z2', 'Z3', ] and len(symbols) >=1):\n",
    "    try:\n",
    "      word['Sign'] = signs_mapper[symbols[-2]]\n",
    "    except:\n",
    "      try:\n",
    "        word['Sign'] = signs_mapper[symbols[-2][:-1]]\n",
    "      except:\n",
    "        print(word)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"words-final-without-reputation.json\", \"w\") as outfile: \n",
    "    json.dump(words, outfile, indent = 4, ensure_ascii=False, sort_keys=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = []\n",
    "seen = set()\n",
    "\n",
    "for word in words:\n",
    "  identifier = (word['Sign'], word['Egyptian'])\n",
    "  if identifier not in seen:\n",
    "    unique_words.append(word)\n",
    "    seen.add(identifier)\n",
    "\n",
    "words = unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8523"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dictionary-scanning-P0VcKHvV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
